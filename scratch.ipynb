{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:58:43.457380Z",
     "start_time": "2024-03-05T23:58:42.773779Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_projects():\n",
    "    command = [\"uctl\", \"get\", \"project\", \"-o\", \"json\"]\n",
    "\n",
    "    try:\n",
    "        projects_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        # print(projects_raw.stdout)\n",
    "\n",
    "        projects_json = json.loads(projects_raw.stdout)\n",
    "        \n",
    "        out_dict = {\n",
    "            \"id\": [],\n",
    "            \"name\": [],\n",
    "            \"domains\": [],\n",
    "            \"description\": [],\n",
    "            \"labels\": [],\n",
    "        }\n",
    "        \n",
    "        for this_project in projects_json:\n",
    "            # print(str(this_project))\n",
    "            \n",
    "            out_dict[\"id\"].append(this_project[\"id\"])\n",
    "            \n",
    "            if \"name\" in this_project.keys():\n",
    "                out_dict[\"name\"].append(this_project[\"name\"])\n",
    "            else:\n",
    "                out_dict[\"name\"].append(\"\")\n",
    "                \n",
    "            domains_list = []\n",
    "            for i in range(0, len(this_project[\"domains\"])):\n",
    "                domains_list.append(this_project[\"domains\"][i][\"id\"])\n",
    "            out_dict[\"domains\"].append(str(domains_list))\n",
    "                \n",
    "            if \"description\" in this_project.keys():\n",
    "                out_dict[\"description\"].append(this_project[\"description\"])\n",
    "            else:\n",
    "                out_dict[\"description\"].append(\"\")\n",
    "                            \n",
    "            labels_list = []\n",
    "            if \"labels\" in this_project.keys():\n",
    "                if \"values\" in this_project[\"labels\"].keys():\n",
    "                    for key in this_project[\"labels\"][\"values\"].keys():\n",
    "                        labels_list.append(str(key) + \":\" + this_project[\"labels\"][\"values\"][key])\n",
    "            out_dict[\"labels\"].append(str(labels_list))    \n",
    "                \n",
    "        out_df = pd.DataFrame(out_dict)\n",
    "        return out_df\n",
    "\n",
    "    except subprocess.SubprocessError as e:\n",
    "        print(\"Error:\", e)\n",
    "        \n",
    "# projects_df = get_projects()\n",
    "# projects_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_workflows(project: str, domain: str):\n",
    "    command = [\"uctl\", \"get\", \"workflows\", \"-p\", project, \"-d\", domain, \"-o\", \"json\"]\n",
    "\n",
    "    try:\n",
    "        workflows_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        # print(workflows_raw.stdout)\n",
    "\n",
    "        workflows_json = json.loads(workflows_raw.stdout)\n",
    "\n",
    "        out_dict = {\n",
    "            \"project\": [],\n",
    "            \"domain\": [],\n",
    "            \"workflow_name\": [],\n",
    "        }\n",
    "\n",
    "        if isinstance(workflows_json, list):\n",
    "            for this_workflow in workflows_json:\n",
    "                out_dict[\"project\"].append(this_workflow[\"id\"][\"project\"])\n",
    "                out_dict[\"domain\"].append(this_workflow[\"id\"][\"domain\"])\n",
    "                out_dict[\"workflow_name\"].append(this_workflow[\"id\"][\"name\"])\n",
    "        else:\n",
    "            out_dict[\"project\"].append(workflows_json[\"id\"][\"project\"])\n",
    "            out_dict[\"domain\"].append(workflows_json[\"id\"][\"domain\"])\n",
    "            out_dict[\"workflow_name\"].append(workflows_json[\"id\"][\"name\"])\n",
    "            \n",
    "        out_df = pd.DataFrame(out_dict)\n",
    "        return out_df\n",
    "\n",
    "    except subprocess.SubprocessError as e:\n",
    "        print(\"Error:\", e)\n",
    "        \n",
    "# workflow_names_df = get_workflows(\"my-new-project\", \"development\")\n",
    "# workflow_names_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:58:46.988968Z",
     "start_time": "2024-03-05T23:58:46.984886Z"
    }
   },
   "id": "3bc47bae6a076192"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_workflow_versions(workflow_names_df: pd.DataFrame):\n",
    "    \n",
    "    # workflow_names_df = workflow_names_df[:10]\n",
    "    \n",
    "    out_dict = {\n",
    "        \"project\": [],\n",
    "        \"domain\": [],\n",
    "        \"workflow_name\": [],\n",
    "        \"workflow_version\": [],\n",
    "        \"created_at\": [],\n",
    "    }\n",
    "    \n",
    "    for i in range(0, workflow_names_df.shape[0]):\n",
    "        this_project = workflow_names_df.at[i, \"project\"]\n",
    "        this_domain = workflow_names_df.at[i, \"domain\"]\n",
    "        this_workflow_name = workflow_names_df.at[i, \"workflow_name\"]\n",
    "    \n",
    "        command = [\"uctl\", \"get\", \"workflow\", \"-p\", this_project, \"-d\", this_domain, this_workflow_name, \"-o\", \"json\"]\n",
    "        \n",
    "        try:\n",
    "            workflow_versions_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "            # print(workflow_versions_raw.stdout)\n",
    "    \n",
    "            workflow_versions_json = json.loads(workflow_versions_raw.stdout)\n",
    "            \n",
    "            if isinstance(workflow_versions_json, list):\n",
    "                for this_workflow in workflow_versions_json: \n",
    "                    out_dict[\"project\"].append(this_workflow[\"id\"][\"project\"])\n",
    "                    out_dict[\"domain\"].append(this_workflow[\"id\"][\"domain\"])\n",
    "                    out_dict[\"workflow_name\"].append(this_workflow[\"id\"][\"name\"])\n",
    "                    out_dict[\"workflow_version\"].append(this_workflow[\"id\"][\"version\"])\n",
    "                    out_dict[\"created_at\"].append(this_workflow[\"closure\"][\"createdAt\"])\n",
    "            else: # special case where there is only a single workflow version\n",
    "                out_dict[\"project\"].append(workflow_versions_json[\"id\"][\"project\"])\n",
    "                out_dict[\"domain\"].append(workflow_versions_json[\"id\"][\"domain\"])\n",
    "                out_dict[\"workflow_name\"].append(workflow_versions_json[\"id\"][\"name\"])\n",
    "                out_dict[\"workflow_version\"].append(workflow_versions_json[\"id\"][\"version\"])\n",
    "                out_dict[\"created_at\"].append(workflow_versions_json[\"closure\"][\"createdAt\"])\n",
    "                \n",
    "\n",
    "        except subprocess.SubprocessError as e:\n",
    "            print(\"Error:\", e)\n",
    "            \n",
    "    out_df = pd.DataFrame(out_dict)\n",
    "    return out_df\n",
    "        \n",
    "# workflow_versions_df = get_workflow_versions(workflow_names_df)\n",
    "# workflow_versions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:58:55.033175Z",
     "start_time": "2024-03-05T23:58:55.028228Z"
    }
   },
   "id": "42d29cd7bcc8cba8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_tasks(project: str, domain: str):\n",
    "    command = [\"uctl\", \"get\", \"tasks\", \"-p\", project, \"-d\", domain, \"-o\", \"json\"]\n",
    "\n",
    "    try:\n",
    "        tasks_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        # print(tasks_raw.stdout)\n",
    "\n",
    "        tasks_json = json.loads(tasks_raw.stdout)\n",
    "\n",
    "        out_dict = {\n",
    "            \"project\": [],\n",
    "            \"domain\": [],\n",
    "            \"task_name\": [],\n",
    "            \"task_version\": [],\n",
    "        }\n",
    "        \n",
    "        if isinstance(tasks_json, list):\n",
    "            for this_task in tasks_json:\n",
    "                out_dict[\"project\"].append(this_task[\"id\"][\"project\"])\n",
    "                out_dict[\"domain\"].append(this_task[\"id\"][\"domain\"])\n",
    "                out_dict[\"task_name\"].append(this_task[\"id\"][\"name\"])\n",
    "                out_dict[\"task_version\"].append(this_task[\"id\"][\"version\"])\n",
    "        else:\n",
    "            out_dict[\"project\"].append(tasks_json[\"id\"][\"project\"])\n",
    "            out_dict[\"domain\"].append(tasks_json[\"id\"][\"domain\"])\n",
    "            out_dict[\"task_name\"].append(tasks_json[\"id\"][\"name\"])\n",
    "            out_dict[\"task_version\"].append(tasks_json[\"id\"][\"version\"])\n",
    "            \n",
    "        out_df = pd.DataFrame(out_dict)\n",
    "        return out_df\n",
    "\n",
    "    except subprocess.SubprocessError as e:\n",
    "        print(\"Error:\", e)\n",
    "        \n",
    "# tasks_and_versions_df = get_tasks(\"my-new-project\", \"development\")\n",
    "# task_names_df = tasks_and_versions_df[[\"project\", \"domain\", \"task_name\"]].drop_duplicates().reset_index(drop=True)\n",
    "# task_names_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:59:03.108991Z",
     "start_time": "2024-03-05T23:59:03.103620Z"
    }
   },
   "id": "5580a04c89f9b42c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_task_versions(task_names_df: pd.DataFrame):\n",
    "    \n",
    "    # task_names_df = task_names_df[:2]\n",
    "    \n",
    "    out_dict = {\n",
    "        \"project\": [],\n",
    "        \"domain\": [],\n",
    "        \"task_name\": [],\n",
    "        \"task_version\": [],\n",
    "        \"created_at\": [],\n",
    "    }\n",
    "    \n",
    "    for i in range(0, task_names_df.shape[0]):\n",
    "        this_project = task_names_df.at[i, \"project\"]\n",
    "        this_domain = task_names_df.at[i, \"domain\"]\n",
    "        this_task_name = task_names_df.at[i, \"task_name\"]\n",
    "    \n",
    "        command = [\"uctl\", \"get\", \"task\", \"-p\", this_project, \"-d\", this_domain, this_task_name, \"-o\", \"json\"]\n",
    "        \n",
    "        try:\n",
    "            task_versions_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "            # print(task_versions_raw.stdout)\n",
    "    \n",
    "            task_versions_json = json.loads(task_versions_raw.stdout)\n",
    "            \n",
    "            if isinstance(task_versions_json, list):\n",
    "                for this_task in task_versions_json:\n",
    "                    # print(str(this_task))\n",
    "                    out_dict[\"project\"].append(this_task[\"id\"][\"project\"])\n",
    "                    out_dict[\"domain\"].append(this_task[\"id\"][\"domain\"])\n",
    "                    out_dict[\"task_name\"].append(this_task[\"id\"][\"name\"])\n",
    "                    out_dict[\"task_version\"].append(this_task[\"id\"][\"version\"])\n",
    "                    out_dict[\"created_at\"].append(this_task[\"closure\"][\"createdAt\"])\n",
    "            else: # special case where only one version exists\n",
    "                out_dict[\"project\"].append(task_versions_json[\"id\"][\"project\"])\n",
    "                out_dict[\"domain\"].append(task_versions_json[\"id\"][\"domain\"])\n",
    "                out_dict[\"task_name\"].append(task_versions_json[\"id\"][\"name\"])\n",
    "                out_dict[\"task_version\"].append(task_versions_json[\"id\"][\"version\"])\n",
    "                out_dict[\"created_at\"].append(task_versions_json[\"closure\"][\"createdAt\"])\n",
    "                \n",
    "        except subprocess.SubprocessError as e:\n",
    "            print(\"Error:\", e)\n",
    "            \n",
    "    out_df = pd.DataFrame(out_dict)\n",
    "    return out_df\n",
    "        \n",
    "# task_versions_df = get_task_versions(task_names_df)\n",
    "# task_versions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:59:07.431442Z",
     "start_time": "2024-03-05T23:59:07.423904Z"
    }
   },
   "id": "833f52f29ccf263b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_launchplans(project: str, domain: str):\n",
    "    command = [\"uctl\", \"get\", \"launchplan\", \"-p\", project, \"-d\", domain, \"-o\", \"json\"]\n",
    "\n",
    "    try:\n",
    "        launplans_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        # print(launplans_raw.stdout)\n",
    "\n",
    "        launchplans_json = json.loads(launplans_raw.stdout)\n",
    "\n",
    "        out_dict = {\n",
    "            \"project\": [],\n",
    "            \"domain\": [],\n",
    "            \"launchplan_name\": [],\n",
    "            \"launchplan_version\": [],\n",
    "        }\n",
    "        \n",
    "        if isinstance(launchplans_json, list):\n",
    "            for this_launchplan in launchplans_json:\n",
    "                out_dict[\"project\"].append(this_launchplan[\"id\"][\"project\"])\n",
    "                out_dict[\"domain\"].append(this_launchplan[\"id\"][\"domain\"])\n",
    "                out_dict[\"launchplan_name\"].append(this_launchplan[\"id\"][\"name\"])\n",
    "                out_dict[\"launchplan_version\"].append(this_launchplan[\"id\"][\"version\"])\n",
    "        else:\n",
    "            out_dict[\"project\"].append(launchplans_json[\"id\"][\"project\"])\n",
    "            out_dict[\"domain\"].append(launchplans_json[\"id\"][\"domain\"])\n",
    "            out_dict[\"launchplan_name\"].append(launchplans_json[\"id\"][\"name\"])\n",
    "            out_dict[\"launchplan_version\"].append(launchplans_json[\"id\"][\"version\"])\n",
    "\n",
    "        out_df = pd.DataFrame(out_dict)\n",
    "        return out_df\n",
    "\n",
    "    except subprocess.SubprocessError as e:\n",
    "        print(\"Error:\", e)\n",
    "        \n",
    "# launchplans_and_versions_df = get_launchplans(\"flytesnacks\", \"development\")\n",
    "# launchplan_names_df = launchplans_and_versions_df[[\"project\", \"domain\", \"launchplan_name\"]].drop_duplicates().reset_index(drop=True)\n",
    "# launchplan_names_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:59:12.111453Z",
     "start_time": "2024-03-05T23:59:12.107025Z"
    }
   },
   "id": "27bcbbc1cb1f9c5e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_launchplan_versions(launchplan_names_df: pd.DataFrame):\n",
    "    \n",
    "    # launchplan_names_df = launchplan_names_df[:2]\n",
    "    \n",
    "    out_dict = {\n",
    "        \"project\": [],\n",
    "        \"domain\": [],\n",
    "        \"launchplan_name\": [],\n",
    "        \"launchplan_version\": [],\n",
    "        \"created_at\": [],\n",
    "    }\n",
    "    \n",
    "    for i in range(0, launchplan_names_df.shape[0]):\n",
    "        this_project = launchplan_names_df.at[i, \"project\"]\n",
    "        this_domain = launchplan_names_df.at[i, \"domain\"]\n",
    "        this_workflow_name = launchplan_names_df.at[i, \"launchplan_name\"]\n",
    "    \n",
    "        command = [\"uctl\", \"get\", \"launchplan\", \"-p\", this_project, \"-d\", this_domain, this_workflow_name, \"-o\", \"json\"]\n",
    "        \n",
    "        try:\n",
    "            launchplan_versions_raw = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "            # print(launchplan_versions_raw.stdout)\n",
    "    \n",
    "            launchplan_versions_json = json.loads(launchplan_versions_raw.stdout)\n",
    "            \n",
    "            if isinstance(launchplan_versions_json, list):\n",
    "                for this_launchplan in launchplan_versions_json: \n",
    "                    out_dict[\"project\"].append(this_launchplan[\"id\"][\"project\"])\n",
    "                    out_dict[\"domain\"].append(this_launchplan[\"id\"][\"domain\"])\n",
    "                    out_dict[\"launchplan_name\"].append(this_launchplan[\"id\"][\"name\"])\n",
    "                    out_dict[\"launchplan_version\"].append(this_launchplan[\"id\"][\"version\"])\n",
    "                    out_dict[\"created_at\"].append(this_launchplan[\"closure\"][\"createdAt\"])\n",
    "            else: # special case where there is only a single workflow version\n",
    "                out_dict[\"project\"].append(launchplan_versions_json[\"id\"][\"project\"])\n",
    "                out_dict[\"domain\"].append(launchplan_versions_json[\"id\"][\"domain\"])\n",
    "                out_dict[\"launchplan_name\"].append(launchplan_versions_json[\"id\"][\"name\"])\n",
    "                out_dict[\"launchplan_version\"].append(launchplan_versions_json[\"id\"][\"version\"])\n",
    "                out_dict[\"created_at\"].append(launchplan_versions_json[\"closure\"][\"createdAt\"])\n",
    "                \n",
    "\n",
    "        except subprocess.SubprocessError as e:\n",
    "            print(\"Error:\", e)\n",
    "            \n",
    "    out_df = pd.DataFrame(out_dict)\n",
    "    return out_df\n",
    "        \n",
    "# launchplan_versions_df = get_launchplan_versions(launchplan_names_df)\n",
    "# launchplan_versions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:59:16.502462Z",
     "start_time": "2024-03-05T23:59:16.498020Z"
    }
   },
   "id": "aee51e3551683198"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: stress-test; domain: development\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'stress-test', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'stress-test', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'stress-test', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: stress-test; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'stress-test', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'stress-test', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'stress-test', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: stress-test; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'stress-test', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'stress-test', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'stress-test', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: my-new-project; domain: development\n",
      "id: my-new-project; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'my-new-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'my-new-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'my-new-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: my-new-project; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'my-new-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'my-new-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'my-new-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: gpu-accelerator-tests; domain: development\n",
      "id: gpu-accelerator-tests; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'gpu-accelerator-tests', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'gpu-accelerator-tests', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'gpu-accelerator-tests', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: gpu-accelerator-tests; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'gpu-accelerator-tests', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'gpu-accelerator-tests', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'gpu-accelerator-tests', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: hoover-test-project; domain: development\n",
      "id: hoover-test-project; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'hoover-test-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'hoover-test-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'hoover-test-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: hoover-test-project; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'hoover-test-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'hoover-test-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'hoover-test-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: union-health-monitoring; domain: development\n",
      "id: union-health-monitoring; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'union-health-monitoring', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'union-health-monitoring', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'union-health-monitoring', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: union-health-monitoring; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'union-health-monitoring', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'union-health-monitoring', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'union-health-monitoring', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: wine-classification-2; domain: development\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'wine-classification-2', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'wine-classification-2', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'wine-classification-2', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: wine-classification-2; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'wine-classification-2', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'wine-classification-2', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'wine-classification-2', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: wine-classification-2; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'wine-classification-2', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'wine-classification-2', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'wine-classification-2', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: tmls-2023; domain: development\n",
      "id: tmls-2023; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'tmls-2023', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'tmls-2023', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'tmls-2023', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: tmls-2023; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'tmls-2023', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'tmls-2023', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'tmls-2023', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: ml-workflows; domain: development\n",
      "id: ml-workflows; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'ml-workflows', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'ml-workflows', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'ml-workflows', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: ml-workflows; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'ml-workflows', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'ml-workflows', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'ml-workflows', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: autodoc; domain: development\n",
      "id: autodoc; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'autodoc', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'autodoc', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'autodoc', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: autodoc; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'autodoc', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'autodoc', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'autodoc', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: sara-wine-classification; domain: development\n",
      "id: sara-wine-classification; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'sara-wine-classification', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'sara-wine-classification', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'sara-wine-classification', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: sara-wine-classification; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'sara-wine-classification', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'sara-wine-classification', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'sara-wine-classification', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: votta-test-project; domain: development\n",
      "id: votta-test-project; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'votta-test-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'votta-test-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'votta-test-project', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: votta-test-project; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'votta-test-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'votta-test-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'votta-test-project', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: wine-classification; domain: development\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'wine-classification', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'wine-classification', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'wine-classification', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: wine-classification; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'wine-classification', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'wine-classification', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'wine-classification', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: wine-classification; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'wine-classification', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'wine-classification', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'wine-classification', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: llm-fine-tuning; domain: development\n",
      "id: llm-fine-tuning; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'llm-fine-tuning', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'llm-fine-tuning', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'llm-fine-tuning', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: llm-fine-tuning; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'llm-fine-tuning', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'llm-fine-tuning', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'llm-fine-tuning', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: onboarding; domain: development\n",
      "id: onboarding; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'onboarding', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'onboarding', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'onboarding', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: onboarding; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'onboarding', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'onboarding', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'onboarding', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: union; domain: development\n",
      "id: union; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'union', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'union', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'union', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: union; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'union', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'union', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'union', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: zeryx-demo; domain: development\n",
      "id: zeryx-demo; domain: staging\n",
      "id: zeryx-demo; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'zeryx-demo', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'zeryx-demo', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'zeryx-demo', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flyte-attendant; domain: development\n",
      "id: flyte-attendant; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flyte-attendant', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flyte-attendant', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flyte-attendant', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flyte-attendant; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flyte-attendant', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flyte-attendant', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flyte-attendant', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flyteexamples; domain: development\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flyteexamples', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flyteexamples', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flyteexamples', '-d', 'development', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flyteexamples; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flyteexamples', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flyteexamples', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flyteexamples', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flyteexamples; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flyteexamples', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flyteexamples', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flyteexamples', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flytetester; domain: development\n",
      "Error: Command '['uctl', 'get', 'task', '-p', 'flytetester', '-d', 'development', 'workflows.example.task_with_bayes_reqs', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flytetester', '-d', 'development', 'workflows.example.wf', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flytetester; domain: staging\n",
      "id: flytetester; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flytetester', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flytetester', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flytetester', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flytesnacks; domain: development\n",
      "Error: Command '['uctl', 'get', 'workflow', '-p', 'flytesnacks', '-d', 'development', 'advanced_composition.subworkflow.slope_intercept_wf', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flytesnacks', '-d', 'development', 'advanced.wf', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flytesnacks; domain: staging\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flytesnacks', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flytesnacks', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flytesnacks', '-d', 'staging', '-o', 'json']' returned non-zero exit status 1.\n",
      "id: flytesnacks; domain: production\n",
      "Error: Command '['uctl', 'get', 'workflows', '-p', 'flytesnacks', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'tasks', '-p', 'flytesnacks', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n",
      "Error: Command '['uctl', 'get', 'launchplan', '-p', 'flytesnacks', '-d', 'production', '-o', 'json']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def get_all_entities():\n",
    "    all_projects_df = get_projects()\n",
    "    \n",
    "    # # testing\n",
    "    # all_projects_df = all_projects_df[all_projects_df[\"id\"] == \"flytesnacks\"].reset_index(drop=True)\n",
    "    \n",
    "    workflow_versions_df_list = []\n",
    "    task_versions_df_list = []\n",
    "    launchplan_versions_df_list = []\n",
    "    \n",
    "    for i in range(0, all_projects_df.shape[0]):\n",
    "        this_id = all_projects_df.at[i, \"id\"]\n",
    "        domains_string_list = all_projects_df.at[i, \"domains\"]\n",
    "        domains_list = ast.literal_eval(domains_string_list)\n",
    "        for this_domain in domains_list:\n",
    "            print(\"id: {}; domain: {}\".format(this_id, this_domain))\n",
    "            \n",
    "            workflow_names_df = get_workflows(this_id, this_domain)\n",
    "            if isinstance(workflow_names_df, pd.DataFrame):\n",
    "                \n",
    "                # # testing\n",
    "                # workflow_names_df = workflow_names_df[:1]\n",
    "                \n",
    "                workflow_versions_df = get_workflow_versions(workflow_names_df)\n",
    "                workflow_versions_df_list.append(workflow_versions_df)\n",
    "            \n",
    "            task_names_df = get_tasks(this_id, this_domain)\n",
    "            if isinstance(task_names_df, pd.DataFrame):\n",
    "                \n",
    "                # # testing\n",
    "                # task_names_df = task_names_df[:1]\n",
    "                \n",
    "                task_versions_df = get_task_versions(task_names_df)\n",
    "                task_versions_df_list.append(task_versions_df)\n",
    "            \n",
    "            launchplan_names_df = get_launchplans(this_id, this_domain)\n",
    "            if isinstance(launchplan_names_df, pd.DataFrame):\n",
    "                \n",
    "                # # testing\n",
    "                # launchplan_names_df = launchplan_names_df[:1]\n",
    "                \n",
    "                launchplan_versions_df = get_launchplan_versions(launchplan_names_df)\n",
    "                launchplan_versions_df_list.append(launchplan_versions_df)\n",
    "                \n",
    "    all_worfkflows_df = pd.concat(workflow_versions_df_list)\n",
    "    all_tasks_df = pd.concat(task_versions_df_list)\n",
    "    all_launchplans_df = pd.concat(launchplan_versions_df_list)\n",
    "    \n",
    "    return all_worfkflows_df, all_tasks_df, all_launchplans_df\n",
    "\n",
    "                        \n",
    "wf, task, lp = get_all_entities()  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T02:02:54.985699Z",
     "start_time": "2024-03-06T00:01:06.799738Z"
    }
   },
   "id": "4f1de29237c7cba"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "wf.to_pickle('workflow_versions_df.pkl')\n",
    "task.to_pickle('task_versions_df.pkl')\n",
    "lp.to_pickle('launchplan_versions_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T02:02:54.998472Z",
     "start_time": "2024-03-06T02:02:54.980035Z"
    }
   },
   "id": "200ae4446d23be75"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                   project       domain  \\\n0           my-new-project  development   \n0    gpu-accelerator-tests  development   \n1    gpu-accelerator-tests  development   \n2    gpu-accelerator-tests  development   \n0      hoover-test-project  development   \n..                     ...          ...   \n493            flytesnacks  development   \n494            flytesnacks  development   \n495            flytesnacks  development   \n496            flytesnacks  development   \n497            flytesnacks  development   \n\n                                         workflow_name  \\\n0                                 workflows.example.wf   \n0    workflows.gpu_accelerator_tests.no_gpu_acceler...   \n1    workflows.gpu_accelerator_tests.with_defined_g...   \n2    workflows.gpu_accelerator_tests.with_defined_g...   \n0    child_directory.python_file_workflow.classname...   \n..                                                 ...   \n493                                     basics.deck.wf   \n494                                     basics.deck.wf   \n495                                     basics.deck.wf   \n496                                     basics.deck.wf   \n497                                     basics.deck.wf   \n\n             workflow_version                   created_at  \n0      MCxs3EE5x2S8JsBYpQ-lDg  2024-02-13T23:08:17.690157Z  \n0    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:33.391902Z  \n1    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:31.079066Z  \n2    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:32.540036Z  \n0      kq00XHtdzIo35caDHWv0fA  2024-02-13T21:06:39.763311Z  \n..                        ...                          ...  \n493                  v0.3.212  2023-07-17T20:52:49.553819Z  \n494                  v0.3.216  2023-08-07T18:22:20.119722Z  \n495                  v0.3.218  2023-08-15T21:47:21.425102Z  \n496                  v0.3.219  2023-08-25T20:18:56.063843Z  \n497                  v0.3.220  2023-08-29T19:45:13.499034Z  \n\n[1540 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>workflow_name</th>\n      <th>workflow_version</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>workflows.example.wf</td>\n      <td>MCxs3EE5x2S8JsBYpQ-lDg</td>\n      <td>2024-02-13T23:08:17.690157Z</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.no_gpu_acceler...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:33.391902Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.with_defined_g...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:31.079066Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.with_defined_g...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:32.540036Z</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>hoover-test-project</td>\n      <td>development</td>\n      <td>child_directory.python_file_workflow.classname...</td>\n      <td>kq00XHtdzIo35caDHWv0fA</td>\n      <td>2024-02-13T21:06:39.763311Z</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>basics.deck.wf</td>\n      <td>v0.3.212</td>\n      <td>2023-07-17T20:52:49.553819Z</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>basics.deck.wf</td>\n      <td>v0.3.216</td>\n      <td>2023-08-07T18:22:20.119722Z</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>basics.deck.wf</td>\n      <td>v0.3.218</td>\n      <td>2023-08-15T21:47:21.425102Z</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>basics.deck.wf</td>\n      <td>v0.3.219</td>\n      <td>2023-08-25T20:18:56.063843Z</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>basics.deck.wf</td>\n      <td>v0.3.220</td>\n      <td>2023-08-29T19:45:13.499034Z</td>\n    </tr>\n  </tbody>\n</table>\n<p>1540 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T02:47:27.119584Z",
     "start_time": "2024-03-06T02:47:27.111966Z"
    }
   },
   "id": "686c8e643f54d44e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                   project       domain  \\\n0           my-new-project  development   \n1           my-new-project  development   \n2           my-new-project  development   \n0    gpu-accelerator-tests  development   \n1    gpu-accelerator-tests  development   \n..                     ...          ...   \n641            flytesnacks  development   \n642            flytesnacks  development   \n643            flytesnacks  development   \n644            flytesnacks  development   \n645            flytesnacks  development   \n\n                                             task_name  \\\n0                    workflows.example.greeting_length   \n1                          workflows.example.say_hello   \n2               workflows.single_task.single_task_demo   \n0    workflows.gpu_accelerator_tests.no_gpu_acceler...   \n1    workflows.gpu_accelerator_tests.with_defined_g...   \n..                                                 ...   \n641             sam.workflow.convert_to_tar_and_upload   \n642             sam.workflow.convert_to_tar_and_upload   \n643             sam.workflow.convert_to_tar_and_upload   \n644             sam.workflow.convert_to_tar_and_upload   \n645             sam.workflow.convert_to_tar_and_upload   \n\n                 task_version                   created_at  \n0      MCxs3EE5x2S8JsBYpQ-lDg  2024-02-13T23:08:17.525720Z  \n1      MCxs3EE5x2S8JsBYpQ-lDg  2024-02-13T23:08:17.386040Z  \n2      q1HylXqel9m7HeH3Xtg_ag  2024-02-13T23:05:10.103033Z  \n0    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:33.122006Z  \n1    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:32.101509Z  \n..                        ...                          ...  \n641    _4pugFhiKiYjXnAgyuaZaw  2024-02-27T16:00:32.935891Z  \n642    Z7nl--qTR661w4TRRCyx3Q  2024-02-27T14:27:20.698538Z  \n643    HM3BtzUsG5KO9JWkyLb8nQ  2024-02-27T13:57:28.354485Z  \n644    ZLaXA4vjjTIw9iJ4jZIL3w  2024-02-27T13:52:04.419695Z  \n645    21bDUGQltb7rXXTumJm-kg  2024-02-27T13:43:36.917271Z  \n\n[14429 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>task_name</th>\n      <th>task_version</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>workflows.example.greeting_length</td>\n      <td>MCxs3EE5x2S8JsBYpQ-lDg</td>\n      <td>2024-02-13T23:08:17.525720Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>workflows.example.say_hello</td>\n      <td>MCxs3EE5x2S8JsBYpQ-lDg</td>\n      <td>2024-02-13T23:08:17.386040Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>workflows.single_task.single_task_demo</td>\n      <td>q1HylXqel9m7HeH3Xtg_ag</td>\n      <td>2024-02-13T23:05:10.103033Z</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.no_gpu_acceler...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:33.122006Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.with_defined_g...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:32.101509Z</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>sam.workflow.convert_to_tar_and_upload</td>\n      <td>_4pugFhiKiYjXnAgyuaZaw</td>\n      <td>2024-02-27T16:00:32.935891Z</td>\n    </tr>\n    <tr>\n      <th>642</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>sam.workflow.convert_to_tar_and_upload</td>\n      <td>Z7nl--qTR661w4TRRCyx3Q</td>\n      <td>2024-02-27T14:27:20.698538Z</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>sam.workflow.convert_to_tar_and_upload</td>\n      <td>HM3BtzUsG5KO9JWkyLb8nQ</td>\n      <td>2024-02-27T13:57:28.354485Z</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>sam.workflow.convert_to_tar_and_upload</td>\n      <td>ZLaXA4vjjTIw9iJ4jZIL3w</td>\n      <td>2024-02-27T13:52:04.419695Z</td>\n    </tr>\n    <tr>\n      <th>645</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>sam.workflow.convert_to_tar_and_upload</td>\n      <td>21bDUGQltb7rXXTumJm-kg</td>\n      <td>2024-02-27T13:43:36.917271Z</td>\n    </tr>\n  </tbody>\n</table>\n<p>14429 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T02:47:37.218164Z",
     "start_time": "2024-03-06T02:47:37.205252Z"
    }
   },
   "id": "19a84f1cfa4bbcb7"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                   project       domain  \\\n0           my-new-project  development   \n1           my-new-project  development   \n0    gpu-accelerator-tests  development   \n1    gpu-accelerator-tests  development   \n2    gpu-accelerator-tests  development   \n..                     ...          ...   \n820            flytesnacks  development   \n821            flytesnacks  development   \n822            flytesnacks  development   \n823            flytesnacks  development   \n824            flytesnacks  development   \n\n                                       launchplan_name  \\\n0                                 workflows.example.wf   \n1     .flytegen.workflows.single_task.single_task_demo   \n0    workflows.gpu_accelerator_tests.no_gpu_acceler...   \n1    workflows.gpu_accelerator_tests.with_defined_g...   \n2    workflows.gpu_accelerator_tests.with_defined_g...   \n..                                                 ...   \n820  src.tasks.lipsync.facerender.animate.animate_f...   \n821  src.tasks.lipsync.facerender.animate.animate_f...   \n822  src.tasks.lipsync.facerender.animate.animate_f...   \n823  src.tasks.lipsync.facerender.animate.animate_f...   \n824  src.tasks.lipsync.facerender.animate.animate_f...   \n\n           launchplan_version                   created_at  \n0      MCxs3EE5x2S8JsBYpQ-lDg  2024-02-13T23:08:18.292186Z  \n1      q1HylXqel9m7HeH3Xtg_ag  2024-02-13T23:05:10.594171Z  \n0    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:34.176303Z  \n1    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:33.010875Z  \n2    670mOt9zqt3gajGPYtIwUg==  2024-01-19T18:05:31.985061Z  \n..                        ...                          ...  \n820    ZxHnHqhRpXoJLJScprqqgQ  2024-02-26T16:42:52.566916Z  \n821    g5xVGaf8RNi1gsbsXnHMuw  2024-02-26T14:04:13.554999Z  \n822    r4HRErescJxgc4bV3wR_RQ  2024-02-26T13:35:01.284452Z  \n823    VlRDGo53INjbceHywPiB6Q  2024-02-26T13:07:14.812347Z  \n824    64bO_c9ySHhyt37Q2mkHCw  2024-02-26T12:33:13.442012Z  \n\n[12752 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>launchplan_name</th>\n      <th>launchplan_version</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>workflows.example.wf</td>\n      <td>MCxs3EE5x2S8JsBYpQ-lDg</td>\n      <td>2024-02-13T23:08:18.292186Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.single_task.single_task_demo</td>\n      <td>q1HylXqel9m7HeH3Xtg_ag</td>\n      <td>2024-02-13T23:05:10.594171Z</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.no_gpu_acceler...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:34.176303Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.with_defined_g...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:33.010875Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gpu-accelerator-tests</td>\n      <td>development</td>\n      <td>workflows.gpu_accelerator_tests.with_defined_g...</td>\n      <td>670mOt9zqt3gajGPYtIwUg==</td>\n      <td>2024-01-19T18:05:31.985061Z</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>820</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>src.tasks.lipsync.facerender.animate.animate_f...</td>\n      <td>ZxHnHqhRpXoJLJScprqqgQ</td>\n      <td>2024-02-26T16:42:52.566916Z</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>src.tasks.lipsync.facerender.animate.animate_f...</td>\n      <td>g5xVGaf8RNi1gsbsXnHMuw</td>\n      <td>2024-02-26T14:04:13.554999Z</td>\n    </tr>\n    <tr>\n      <th>822</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>src.tasks.lipsync.facerender.animate.animate_f...</td>\n      <td>r4HRErescJxgc4bV3wR_RQ</td>\n      <td>2024-02-26T13:35:01.284452Z</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>src.tasks.lipsync.facerender.animate.animate_f...</td>\n      <td>VlRDGo53INjbceHywPiB6Q</td>\n      <td>2024-02-26T13:07:14.812347Z</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>src.tasks.lipsync.facerender.animate.animate_f...</td>\n      <td>64bO_c9ySHhyt37Q2mkHCw</td>\n      <td>2024-02-26T12:33:13.442012Z</td>\n    </tr>\n  </tbody>\n</table>\n<p>12752 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T02:47:40.687165Z",
     "start_time": "2024-03-06T02:47:40.682137Z"
    }
   },
   "id": "cacbb3b11755afa3"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "             project       domain  \\\n0            autodoc  development   \n1            autodoc  development   \n2    flyte-attendant  development   \n3        flytesnacks  development   \n4        flytesnacks  development   \n..               ...          ...   \n295       zeryx-demo  development   \n296       zeryx-demo  development   \n297       zeryx-demo  development   \n298       zeryx-demo  development   \n299       zeryx-demo      staging   \n\n                                         workflow_name  \\\n0                        docai.generate.generate_cloud   \n1                        docai.generate.generate_local   \n2           flyte_attendant.workflows.chat_support.ask   \n3                                               add.wf   \n4                                          advanced.wf   \n..                                                 ...   \n295       workflows.mnist_training_example.grid_search   \n296  workflows.mnist_training_example.mnist_workflo...   \n297                 workflows.neuron.resnet50_infer_wf   \n298                 workflows.ray_example.ray_workflow   \n299                               workflows.example.wf   \n\n             workflow_version                   created_at  \\\n0    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:48.259912Z   \n1    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:47.521984Z   \n2    zd-GIZj7TpYqRfleJCLnbQ==  2023-03-15T16:04:28.576431Z   \n3      9-J01oEmiPE8YsfHxxPn8g  2024-02-12T14:59:01.690505Z   \n4      zBBExGyE2tFuAxjZerd6cQ  2024-02-27T15:06:57.612396Z   \n..                        ...                          ...   \n295  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:57.579404Z   \n296  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:56.462475Z   \n297  Mb5m6j1cc3m9lsGw2me32A==  2023-11-16T19:17:37.636150Z   \n298  M_5qOFZQOR2DxbfpYWPdsw==  2023-11-27T17:48:29.811317Z   \n299                         2  2023-12-05T19:06:21.662703Z   \n\n                           timestamp  \n0   2024-01-11 22:15:48.259912+00:00  \n1   2024-01-11 22:15:47.521984+00:00  \n2   2023-03-15 16:04:28.576431+00:00  \n3   2024-02-12 14:59:01.690505+00:00  \n4   2024-02-27 15:06:57.612396+00:00  \n..                               ...  \n295 2024-01-02 19:49:57.579404+00:00  \n296 2024-01-02 19:49:56.462475+00:00  \n297 2023-11-16 19:17:37.636150+00:00  \n298 2023-11-27 17:48:29.811317+00:00  \n299 2023-12-05 19:06:21.662703+00:00  \n\n[300 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>workflow_name</th>\n      <th>workflow_version</th>\n      <th>created_at</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.generate_cloud</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:48.259912Z</td>\n      <td>2024-01-11 22:15:48.259912+00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.generate_local</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:47.521984Z</td>\n      <td>2024-01-11 22:15:47.521984+00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>flyte-attendant</td>\n      <td>development</td>\n      <td>flyte_attendant.workflows.chat_support.ask</td>\n      <td>zd-GIZj7TpYqRfleJCLnbQ==</td>\n      <td>2023-03-15T16:04:28.576431Z</td>\n      <td>2023-03-15 16:04:28.576431+00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>add.wf</td>\n      <td>9-J01oEmiPE8YsfHxxPn8g</td>\n      <td>2024-02-12T14:59:01.690505Z</td>\n      <td>2024-02-12 14:59:01.690505+00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>advanced.wf</td>\n      <td>zBBExGyE2tFuAxjZerd6cQ</td>\n      <td>2024-02-27T15:06:57.612396Z</td>\n      <td>2024-02-27 15:06:57.612396+00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.grid_search</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:57.579404Z</td>\n      <td>2024-01-02 19:49:57.579404+00:00</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.mnist_workflo...</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:56.462475Z</td>\n      <td>2024-01-02 19:49:56.462475+00:00</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.neuron.resnet50_infer_wf</td>\n      <td>Mb5m6j1cc3m9lsGw2me32A==</td>\n      <td>2023-11-16T19:17:37.636150Z</td>\n      <td>2023-11-16 19:17:37.636150+00:00</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.ray_example.ray_workflow</td>\n      <td>M_5qOFZQOR2DxbfpYWPdsw==</td>\n      <td>2023-11-27T17:48:29.811317Z</td>\n      <td>2023-11-27 17:48:29.811317+00:00</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>zeryx-demo</td>\n      <td>staging</td>\n      <td>workflows.example.wf</td>\n      <td>2</td>\n      <td>2023-12-05T19:06:21.662703Z</td>\n      <td>2023-12-05 19:06:21.662703+00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_latest_df = wf.copy()\n",
    "wf_latest_df[\"timestamp\"] = pd.to_datetime(wf_latest_df[\"created_at\"])\n",
    "wf_latest_df = wf_latest_df.sort_values(by=[\"project\", \"domain\", \"workflow_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "latest_indices = wf_latest_df.groupby([\"project\", \"domain\", \"workflow_name\"])[\"timestamp\"].idxmax()\n",
    "wf_latest_df = wf_latest_df.loc[latest_indices].reset_index(drop=True)\n",
    "wf_latest_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:57:09.020123Z",
     "start_time": "2024-03-06T04:57:09.006762Z"
    }
   },
   "id": "183a04c16620b825"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "        project       domain  \\\n0       autodoc  development   \n1       autodoc  development   \n2       autodoc  development   \n3       autodoc  development   \n4       autodoc  development   \n..          ...          ...   \n384  zeryx-demo  development   \n385  zeryx-demo  development   \n386  zeryx-demo  development   \n387  zeryx-demo      staging   \n388  zeryx-demo      staging   \n\n                                            task_name  \\\n0       docai.generate.download_and_unzip_github_repo   \n1                        docai.generate.generate_html   \n2              docai.generate.get_and_set_open_ai_key   \n3              docai.generate.get_github_access_token   \n4                                docai.generate.parse   \n..                                                ...   \n384   workflows.mnist_training_example.mnist_task_gpu   \n385            workflows.mnist_training_example.train   \n386  workflows.mnist_training_example.validation_loss   \n387                 workflows.example.greeting_length   \n388                       workflows.example.say_hello   \n\n                 task_version                   created_at  \\\n0    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:46.789629Z   \n1    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:47.354163Z   \n2    6HxwAn2dhJByF1FjMiHj-g==  2024-01-10T23:26:58.800831Z   \n3    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:46.678860Z   \n4    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:46.891243Z   \n..                        ...                          ...   \n384  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:56.250244Z   \n385  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:56.011848Z   \n386  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:56.129522Z   \n387                         2  2023-12-05T19:06:21.498265Z   \n388                         2  2023-12-05T19:06:21.395097Z   \n\n                           timestamp  \n0   2024-01-11 22:15:46.789629+00:00  \n1   2024-01-11 22:15:47.354163+00:00  \n2   2024-01-10 23:26:58.800831+00:00  \n3   2024-01-11 22:15:46.678860+00:00  \n4   2024-01-11 22:15:46.891243+00:00  \n..                               ...  \n384 2024-01-02 19:49:56.250244+00:00  \n385 2024-01-02 19:49:56.011848+00:00  \n386 2024-01-02 19:49:56.129522+00:00  \n387 2023-12-05 19:06:21.498265+00:00  \n388 2023-12-05 19:06:21.395097+00:00  \n\n[389 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>task_name</th>\n      <th>task_version</th>\n      <th>created_at</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.download_and_unzip_github_repo</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:46.789629Z</td>\n      <td>2024-01-11 22:15:46.789629+00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.generate_html</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:47.354163Z</td>\n      <td>2024-01-11 22:15:47.354163+00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.get_and_set_open_ai_key</td>\n      <td>6HxwAn2dhJByF1FjMiHj-g==</td>\n      <td>2024-01-10T23:26:58.800831Z</td>\n      <td>2024-01-10 23:26:58.800831+00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.get_github_access_token</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:46.678860Z</td>\n      <td>2024-01-11 22:15:46.678860+00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.parse</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:46.891243Z</td>\n      <td>2024-01-11 22:15:46.891243+00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.mnist_task_gpu</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:56.250244Z</td>\n      <td>2024-01-02 19:49:56.250244+00:00</td>\n    </tr>\n    <tr>\n      <th>385</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.train</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:56.011848Z</td>\n      <td>2024-01-02 19:49:56.011848+00:00</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.validation_loss</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:56.129522Z</td>\n      <td>2024-01-02 19:49:56.129522+00:00</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>zeryx-demo</td>\n      <td>staging</td>\n      <td>workflows.example.greeting_length</td>\n      <td>2</td>\n      <td>2023-12-05T19:06:21.498265Z</td>\n      <td>2023-12-05 19:06:21.498265+00:00</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>zeryx-demo</td>\n      <td>staging</td>\n      <td>workflows.example.say_hello</td>\n      <td>2</td>\n      <td>2023-12-05T19:06:21.395097Z</td>\n      <td>2023-12-05 19:06:21.395097+00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>389 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_latest_df = task.copy()\n",
    "task_latest_df[\"timestamp\"] = pd.to_datetime(task_latest_df[\"created_at\"])\n",
    "task_latest_df = task_latest_df.sort_values(by=[\"project\", \"domain\", \"task_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "latest_indices = task_latest_df.groupby([\"project\", \"domain\", \"task_name\"])[\"timestamp\"].idxmax()\n",
    "task_latest_df = task_latest_df.loc[latest_indices].reset_index(drop=True)\n",
    "task_latest_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:57:09.587682Z",
     "start_time": "2024-03-06T04:57:09.549317Z"
    }
   },
   "id": "85cbc8575bfc882"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "             project       domain  \\\n0            autodoc  development   \n1            autodoc  development   \n2            autodoc  development   \n3    flyte-attendant  development   \n4        flytesnacks  development   \n..               ...          ...   \n239       zeryx-demo  development   \n240       zeryx-demo  development   \n241       zeryx-demo  development   \n242       zeryx-demo  development   \n243       zeryx-demo      staging   \n\n                                       launchplan_name  \\\n0     .flytegen.docai.generate.get_and_set_open_ai_key   \n1                        docai.generate.generate_cloud   \n2                        docai.generate.generate_local   \n3           flyte_attendant.workflows.chat_support.ask   \n4                                    .flytegen.task.t1   \n..                                                 ...   \n239          workflows.example.specific_file_in_dir_wf   \n240                               workflows.example.wf   \n241       workflows.mnist_training_example.grid_search   \n242  workflows.mnist_training_example.mnist_workflo...   \n243                               workflows.example.wf   \n\n           launchplan_version                   created_at  \\\n0    C5oxz70-jD0k6-lmhG0-NQ==  2024-01-08T22:12:12.158655Z   \n1    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:48.775143Z   \n2    1L9EtKryxGRLAP0lsKiOwQ==  2024-01-11T22:15:48.061499Z   \n3    zd-GIZj7TpYqRfleJCLnbQ==  2023-03-15T16:04:28.828732Z   \n4      Yr1wdryFqm_zHNa5DePIgw  2024-02-27T18:45:04.028195Z   \n..                        ...                          ...   \n239  CRZjyrzA3upd5lz59Bk3CA==  2023-12-11T18:39:29.063637Z   \n240  yrE3rfqbKcIXqysZqYwMPg==  2023-12-14T20:51:40.884573Z   \n241  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:58.164018Z   \n242  TqhZBvoTMeSVz2DXACHWcQ==  2024-01-02T19:49:56.983671Z   \n243                         2  2023-12-05T19:06:22.048414Z   \n\n                           timestamp  \n0   2024-01-08 22:12:12.158655+00:00  \n1   2024-01-11 22:15:48.775143+00:00  \n2   2024-01-11 22:15:48.061499+00:00  \n3   2023-03-15 16:04:28.828732+00:00  \n4   2024-02-27 18:45:04.028195+00:00  \n..                               ...  \n239 2023-12-11 18:39:29.063637+00:00  \n240 2023-12-14 20:51:40.884573+00:00  \n241 2024-01-02 19:49:58.164018+00:00  \n242 2024-01-02 19:49:56.983671+00:00  \n243 2023-12-05 19:06:22.048414+00:00  \n\n[244 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>launchplan_name</th>\n      <th>launchplan_version</th>\n      <th>created_at</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>.flytegen.docai.generate.get_and_set_open_ai_key</td>\n      <td>C5oxz70-jD0k6-lmhG0-NQ==</td>\n      <td>2024-01-08T22:12:12.158655Z</td>\n      <td>2024-01-08 22:12:12.158655+00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.generate_cloud</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:48.775143Z</td>\n      <td>2024-01-11 22:15:48.775143+00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>docai.generate.generate_local</td>\n      <td>1L9EtKryxGRLAP0lsKiOwQ==</td>\n      <td>2024-01-11T22:15:48.061499Z</td>\n      <td>2024-01-11 22:15:48.061499+00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>flyte-attendant</td>\n      <td>development</td>\n      <td>flyte_attendant.workflows.chat_support.ask</td>\n      <td>zd-GIZj7TpYqRfleJCLnbQ==</td>\n      <td>2023-03-15T16:04:28.828732Z</td>\n      <td>2023-03-15 16:04:28.828732+00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>.flytegen.task.t1</td>\n      <td>Yr1wdryFqm_zHNa5DePIgw</td>\n      <td>2024-02-27T18:45:04.028195Z</td>\n      <td>2024-02-27 18:45:04.028195+00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.example.specific_file_in_dir_wf</td>\n      <td>CRZjyrzA3upd5lz59Bk3CA==</td>\n      <td>2023-12-11T18:39:29.063637Z</td>\n      <td>2023-12-11 18:39:29.063637+00:00</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.example.wf</td>\n      <td>yrE3rfqbKcIXqysZqYwMPg==</td>\n      <td>2023-12-14T20:51:40.884573Z</td>\n      <td>2023-12-14 20:51:40.884573+00:00</td>\n    </tr>\n    <tr>\n      <th>241</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.grid_search</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:58.164018Z</td>\n      <td>2024-01-02 19:49:58.164018+00:00</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>workflows.mnist_training_example.mnist_workflo...</td>\n      <td>TqhZBvoTMeSVz2DXACHWcQ==</td>\n      <td>2024-01-02T19:49:56.983671Z</td>\n      <td>2024-01-02 19:49:56.983671+00:00</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>zeryx-demo</td>\n      <td>staging</td>\n      <td>workflows.example.wf</td>\n      <td>2</td>\n      <td>2023-12-05T19:06:22.048414Z</td>\n      <td>2023-12-05 19:06:22.048414+00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>244 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launchplan_latest_df = lp.copy()\n",
    "launchplan_latest_df[\"timestamp\"] = pd.to_datetime(launchplan_latest_df[\"created_at\"])\n",
    "launchplan_latest_df = launchplan_latest_df.sort_values(by=[\"project\", \"domain\", \"launchplan_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "latest_indices = launchplan_latest_df.groupby([\"project\", \"domain\", \"launchplan_name\"])[\"timestamp\"].idxmax()\n",
    "launchplan_latest_df = launchplan_latest_df.loc[latest_indices].reset_index(drop=True)\n",
    "launchplan_latest_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:59:23.943669Z",
     "start_time": "2024-03-06T04:59:23.920858Z"
    }
   },
   "id": "39b56cc865fd2a26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_df = wf_latest_df[wf_latest_df[\"workflow_name\"].str.contains(\".flytegen\")]\n",
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e48218d869024b66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_df = task_latest_df[task_latest_df[\"task_name\"].str.contains(\".flytegen\")]\n",
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87b40cd2a96ed9ba"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "                 project       domain  \\\n0                autodoc  development   \n4            flytesnacks  development   \n31           flytetester  development   \n32           flytetester  development   \n57   hoover-test-project  development   \n70       llm-fine-tuning  development   \n71       llm-fine-tuning  development   \n72       llm-fine-tuning  development   \n73       llm-fine-tuning  development   \n74       llm-fine-tuning  development   \n75       llm-fine-tuning  development   \n83        my-new-project  development   \n85            onboarding  development   \n110                union  development   \n211   votta-test-project  development   \n212   votta-test-project  development   \n213   votta-test-project  development   \n214   votta-test-project  development   \n232           zeryx-demo  development   \n\n                                       launchplan_name  \\\n0     .flytegen.docai.generate.get_and_set_open_ai_key   \n4                                    .flytegen.task.t1   \n31   .flytegen.workflows.map_task_repro.dynamic_map...   \n32    .flytegen.workflows.registration.registration_wf   \n57        .flytegen.workflows.test_workflow.hello_task   \n70      .flytegen.flyte_llama.workflows.create_dataset   \n71       .flytegen.flyte_llama.workflows.publish_model   \n72               .flytegen.flyte_llama.workflows.train   \n73     .flytegen.flyte_llama.workflows.tune_batch_size   \n74   .flytegen.flyte_llama.workflows.tune_batch_siz...   \n75   .flytegen.flyte_llama.workflows.tune_batch_siz...   \n83    .flytegen.workflows.single_task.single_task_demo   \n85   .flytegen.workflows.mnist_training_example1.ge...   \n110  .flytegen.core.control_flow.dynamics.count_cha...   \n211  .flytegen.workflows.big_map_task.map_a_mappabl...   \n212         .flytegen.workflows.gpu_selection.gpu_task   \n213        .flytegen.workflows.single_task.single_task   \n214   .flytegen.workflows.single_task.single_task_demo   \n232  .flytegen.flyte_workflows.main.make_inference_...   \n\n                       launchplan_version                   created_at  \\\n0                C5oxz70-jD0k6-lmhG0-NQ==  2024-01-08T22:12:12.158655Z   \n4                  Yr1wdryFqm_zHNa5DePIgw  2024-02-27T18:45:04.028195Z   \n31               FkbMR7Uv0GkoVx1MEOZsjg==  2023-06-02T22:02:22.018151Z   \n32               wnPeKeZ8wpzAi8kiAqxJtg==  2023-05-29T16:51:46.366598Z   \n57               K9X8xa5VKB1o2B7uAYB7yQ==  2024-02-08T22:30:57.569881Z   \n70               -Fj61EwsOp5Y_A22NtOdYQ==  2023-11-16T20:01:55.036300Z   \n71               VENx1zSF-Ps4mhqlzRacwA==  2023-10-21T14:22:05.348069Z   \n72               RsIpgs99a1HWAyex3BKt-w==  2024-01-25T16:09:38.161008Z   \n73               VjtrtNtYHZsMgl3HAKVNXA==  2023-11-16T15:01:09.335263Z   \n74               VxOmngjs7UNi6yHml5UONQ==  2023-11-16T13:43:27.296126Z   \n75               6ddHb0kIzuG9-Pn_fOfxjA==  2023-11-16T13:56:52.387329Z   \n83                 q1HylXqel9m7HeH3Xtg_ag  2024-02-13T23:05:10.594171Z   \n85   61bbdfd5-4ab9-4651-96d1-269ade590793  2023-05-16T18:52:39.151153Z   \n110                              v0.3.187  2023-03-29T06:47:09.486244Z   \n211                IanNKohf_R8rmg1IU95erg  2024-02-01T19:59:21.902047Z   \n212                nbEdG_59DekgyVcyHRtiFg  2024-01-31T23:34:28.987711Z   \n213              5eyUX_sM-NFco0USMJv28w==  2024-01-03T19:42:25.713584Z   \n214              qu32HZIB-1nFULc-X8z7Jw==  2024-01-04T18:24:35.039391Z   \n232              3-BFgNHPT2a06xDmYW8-Wg==  2024-01-02T15:55:59.562592Z   \n\n                           timestamp  \n0   2024-01-08 22:12:12.158655+00:00  \n4   2024-02-27 18:45:04.028195+00:00  \n31  2023-06-02 22:02:22.018151+00:00  \n32  2023-05-29 16:51:46.366598+00:00  \n57  2024-02-08 22:30:57.569881+00:00  \n70  2023-11-16 20:01:55.036300+00:00  \n71  2023-10-21 14:22:05.348069+00:00  \n72  2024-01-25 16:09:38.161008+00:00  \n73  2023-11-16 15:01:09.335263+00:00  \n74  2023-11-16 13:43:27.296126+00:00  \n75  2023-11-16 13:56:52.387329+00:00  \n83  2024-02-13 23:05:10.594171+00:00  \n85  2023-05-16 18:52:39.151153+00:00  \n110 2023-03-29 06:47:09.486244+00:00  \n211 2024-02-01 19:59:21.902047+00:00  \n212 2024-01-31 23:34:28.987711+00:00  \n213 2024-01-03 19:42:25.713584+00:00  \n214 2024-01-04 18:24:35.039391+00:00  \n232 2024-01-02 15:55:59.562592+00:00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project</th>\n      <th>domain</th>\n      <th>launchplan_name</th>\n      <th>launchplan_version</th>\n      <th>created_at</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>autodoc</td>\n      <td>development</td>\n      <td>.flytegen.docai.generate.get_and_set_open_ai_key</td>\n      <td>C5oxz70-jD0k6-lmhG0-NQ==</td>\n      <td>2024-01-08T22:12:12.158655Z</td>\n      <td>2024-01-08 22:12:12.158655+00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flytesnacks</td>\n      <td>development</td>\n      <td>.flytegen.task.t1</td>\n      <td>Yr1wdryFqm_zHNa5DePIgw</td>\n      <td>2024-02-27T18:45:04.028195Z</td>\n      <td>2024-02-27 18:45:04.028195+00:00</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>flytetester</td>\n      <td>development</td>\n      <td>.flytegen.workflows.map_task_repro.dynamic_map...</td>\n      <td>FkbMR7Uv0GkoVx1MEOZsjg==</td>\n      <td>2023-06-02T22:02:22.018151Z</td>\n      <td>2023-06-02 22:02:22.018151+00:00</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>flytetester</td>\n      <td>development</td>\n      <td>.flytegen.workflows.registration.registration_wf</td>\n      <td>wnPeKeZ8wpzAi8kiAqxJtg==</td>\n      <td>2023-05-29T16:51:46.366598Z</td>\n      <td>2023-05-29 16:51:46.366598+00:00</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>hoover-test-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.test_workflow.hello_task</td>\n      <td>K9X8xa5VKB1o2B7uAYB7yQ==</td>\n      <td>2024-02-08T22:30:57.569881Z</td>\n      <td>2024-02-08 22:30:57.569881+00:00</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>llm-fine-tuning</td>\n      <td>development</td>\n      <td>.flytegen.flyte_llama.workflows.create_dataset</td>\n      <td>-Fj61EwsOp5Y_A22NtOdYQ==</td>\n      <td>2023-11-16T20:01:55.036300Z</td>\n      <td>2023-11-16 20:01:55.036300+00:00</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>llm-fine-tuning</td>\n      <td>development</td>\n      <td>.flytegen.flyte_llama.workflows.publish_model</td>\n      <td>VENx1zSF-Ps4mhqlzRacwA==</td>\n      <td>2023-10-21T14:22:05.348069Z</td>\n      <td>2023-10-21 14:22:05.348069+00:00</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>llm-fine-tuning</td>\n      <td>development</td>\n      <td>.flytegen.flyte_llama.workflows.train</td>\n      <td>RsIpgs99a1HWAyex3BKt-w==</td>\n      <td>2024-01-25T16:09:38.161008Z</td>\n      <td>2024-01-25 16:09:38.161008+00:00</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>llm-fine-tuning</td>\n      <td>development</td>\n      <td>.flytegen.flyte_llama.workflows.tune_batch_size</td>\n      <td>VjtrtNtYHZsMgl3HAKVNXA==</td>\n      <td>2023-11-16T15:01:09.335263Z</td>\n      <td>2023-11-16 15:01:09.335263+00:00</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>llm-fine-tuning</td>\n      <td>development</td>\n      <td>.flytegen.flyte_llama.workflows.tune_batch_siz...</td>\n      <td>VxOmngjs7UNi6yHml5UONQ==</td>\n      <td>2023-11-16T13:43:27.296126Z</td>\n      <td>2023-11-16 13:43:27.296126+00:00</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>llm-fine-tuning</td>\n      <td>development</td>\n      <td>.flytegen.flyte_llama.workflows.tune_batch_siz...</td>\n      <td>6ddHb0kIzuG9-Pn_fOfxjA==</td>\n      <td>2023-11-16T13:56:52.387329Z</td>\n      <td>2023-11-16 13:56:52.387329+00:00</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>my-new-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.single_task.single_task_demo</td>\n      <td>q1HylXqel9m7HeH3Xtg_ag</td>\n      <td>2024-02-13T23:05:10.594171Z</td>\n      <td>2024-02-13 23:05:10.594171+00:00</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>onboarding</td>\n      <td>development</td>\n      <td>.flytegen.workflows.mnist_training_example1.ge...</td>\n      <td>61bbdfd5-4ab9-4651-96d1-269ade590793</td>\n      <td>2023-05-16T18:52:39.151153Z</td>\n      <td>2023-05-16 18:52:39.151153+00:00</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>union</td>\n      <td>development</td>\n      <td>.flytegen.core.control_flow.dynamics.count_cha...</td>\n      <td>v0.3.187</td>\n      <td>2023-03-29T06:47:09.486244Z</td>\n      <td>2023-03-29 06:47:09.486244+00:00</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>votta-test-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.big_map_task.map_a_mappabl...</td>\n      <td>IanNKohf_R8rmg1IU95erg</td>\n      <td>2024-02-01T19:59:21.902047Z</td>\n      <td>2024-02-01 19:59:21.902047+00:00</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>votta-test-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.gpu_selection.gpu_task</td>\n      <td>nbEdG_59DekgyVcyHRtiFg</td>\n      <td>2024-01-31T23:34:28.987711Z</td>\n      <td>2024-01-31 23:34:28.987711+00:00</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>votta-test-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.single_task.single_task</td>\n      <td>5eyUX_sM-NFco0USMJv28w==</td>\n      <td>2024-01-03T19:42:25.713584Z</td>\n      <td>2024-01-03 19:42:25.713584+00:00</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>votta-test-project</td>\n      <td>development</td>\n      <td>.flytegen.workflows.single_task.single_task_demo</td>\n      <td>qu32HZIB-1nFULc-X8z7Jw==</td>\n      <td>2024-01-04T18:24:35.039391Z</td>\n      <td>2024-01-04 18:24:35.039391+00:00</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>zeryx-demo</td>\n      <td>development</td>\n      <td>.flytegen.flyte_workflows.main.make_inference_...</td>\n      <td>3-BFgNHPT2a06xDmYW8-Wg==</td>\n      <td>2024-01-02T15:55:59.562592Z</td>\n      <td>2024-01-02 15:55:59.562592+00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = launchplan_latest_df[launchplan_latest_df[\"launchplan_name\"].str.contains(\".flytegen\")]\n",
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:00:00.287819Z",
     "start_time": "2024-03-06T05:00:00.283406Z"
    }
   },
   "id": "d6e4c72e7c2981b8"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "folder_name = \"Library\"\n",
    "library_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "if os.path.exists(library_path):\n",
    "    os.system(f\"rm -rf {library_path}\")\n",
    "\n",
    "os.makedirs(library_path)\n",
    "\n",
    "    \n",
    "for i in range(0, wf_latest_df.shape[0]):\n",
    "    domain_name = wf_latest_df.at[i, \"domain\"]\n",
    "    project_name = wf_latest_df.at[i, \"project\"]\n",
    "    workflow_name = wf_latest_df.at[i, \"workflow_name\"]\n",
    "    if \".flytegen\" in workflow_name:\n",
    "        workflow_name = workflow_name.replace(\".flytegen.\", \"\") + \"-auto_generated\"\n",
    "    \n",
    "    root_path = os.path.join(library_path, domain_name, project_name)\n",
    "    \n",
    "    folders = workflow_name.split(\".\")\n",
    "    file_name = folders.pop() + \".workflow\"\n",
    "    if len(folders) > 0:\n",
    "        folder_path = os.path.join(*folders)\n",
    "        folder_path = os.path.join(root_path, folder_path)\n",
    "    else:\n",
    "        folder_path = root_path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # print(\"folder_path: {}; file:{}; file_path: {}\".format(folder_path, file_name, file_path))\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(\"workflow name: {}\".format(workflow_name))\n",
    "            \n",
    "for i in range(0, task_latest_df.shape[0]):\n",
    "    domain_name = task_latest_df.at[i, \"domain\"]\n",
    "    project_name = task_latest_df.at[i, \"project\"]\n",
    "    task_name = task_latest_df.at[i, \"task_name\"]\n",
    "    if \".flytegen\" in task_name:\n",
    "        task_name = task_name.replace(\".flytegen.\", \"\") + \"-auto_generated\"\n",
    "    \n",
    "    root_path = os.path.join(library_path, domain_name, project_name)\n",
    "    \n",
    "    folders = task_name.split(\".\")\n",
    "    file_name = folders.pop() + \".task\"\n",
    "    if len(folders) > 0:\n",
    "        folder_path = os.path.join(*folders)\n",
    "        folder_path = os.path.join(root_path, folder_path)\n",
    "    else:\n",
    "        folder_path = root_path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # print(\"folder_path: {}; file:{}; file_path: {}\".format(folder_path, file_name, file_path))\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(\"task name: {}\".format(task_name))\n",
    "            \n",
    "for i in range(0, launchplan_latest_df.shape[0]):\n",
    "    domain_name = launchplan_latest_df.at[i, \"domain\"]\n",
    "    project_name = launchplan_latest_df.at[i, \"project\"]\n",
    "    launchplan_name = launchplan_latest_df.at[i, \"launchplan_name\"]\n",
    "    if \".flytegen\" in launchplan_name:\n",
    "        launchplan_name = launchplan_name.replace(\".flytegen.\", \"\") + \"-auto_generated\"\n",
    "    \n",
    "    root_path = os.path.join(library_path, domain_name, project_name)\n",
    "    \n",
    "    folders = launchplan_name.split(\".\")\n",
    "    file_name = folders.pop() + \".launchplan\"\n",
    "    if len(folders) > 0:\n",
    "        folder_path = os.path.join(*folders)\n",
    "        folder_path = os.path.join(root_path, folder_path)\n",
    "    else:\n",
    "        folder_path = root_path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # print(\"folder_path: {}; file:{}; file_path: {}\".format(folder_path, file_name, file_path))\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(\"launchplan name: {}\".format(launchplan_name))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:03:42.410947Z",
     "start_time": "2024-03-06T05:03:42.219012Z"
    }
   },
   "id": "7cbe66228b2683c8"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:09:39.600614Z",
     "start_time": "2024-03-06T05:09:39.596931Z"
    }
   },
   "id": "7a89bb11ade298d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_directory(wf: pd.DataFrame, task: pd.DataFrame, lp: pd.DataFrame):\n",
    "    \n",
    "    wf_latest_df = wf.copy()\n",
    "    wf_latest_df[\"timestamp\"] = pd.to_datetime(wf_latest_df[\"created_at\"])\n",
    "    wf_latest_df = wf_latest_df.sort_values(by=[\"project\", \"domain\", \"workflow_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "    latest_indices = wf_latest_df.groupby([\"project\", \"domain\", \"workflow_name\"])[\"timestamp\"].idxmax()\n",
    "    wf_latest_df = wf_latest_df.loc[latest_indices].reset_index(drop=True)\n",
    "    \n",
    "    task_latest_df = task.copy()\n",
    "    task_latest_df[\"timestamp\"] = pd.to_datetime(task_latest_df[\"created_at\"])\n",
    "    task_latest_df = task_latest_df.sort_values(by=[\"project\", \"domain\", \"task_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "    latest_indices = task_latest_df.groupby([\"project\", \"domain\", \"task_name\"])[\"timestamp\"].idxmax()\n",
    "    task_latest_df = task_latest_df.loc[latest_indices].reset_index(drop=True)\n",
    "    \n",
    "    launchplan_latest_df = lp.copy()\n",
    "    launchplan_latest_df[\"timestamp\"] = pd.to_datetime(launchplan_latest_df[\"created_at\"])\n",
    "    launchplan_latest_df = launchplan_latest_df.sort_values(by=[\"project\", \"domain\", \"launchplan_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "    latest_indices = launchplan_latest_df.groupby([\"project\", \"domain\", \"launchplan_name\"])[\"timestamp\"].idxmax()\n",
    "    launchplan_latest_df = launchplan_latest_df.loc[latest_indices].reset_index(drop=True)\n",
    "    \n",
    "    current_directory = os.getcwd()\n",
    "    folder_name = \"Library\"\n",
    "    library_path = os.path.join(current_directory, folder_name)\n",
    "    \n",
    "    if os.path.exists(library_path):\n",
    "        os.system(f\"rm -rf {library_path}\")\n",
    "    \n",
    "    os.makedirs(library_path)\n",
    "    \n",
    "        \n",
    "    for i in range(0, wf_latest_df.shape[0]):\n",
    "        domain_name = wf_latest_df.at[i, \"domain\"]\n",
    "        project_name = wf_latest_df.at[i, \"project\"]\n",
    "        workflow_name = wf_latest_df.at[i, \"workflow_name\"]\n",
    "        if \".flytegen\" in workflow_name:\n",
    "            workflow_name = workflow_name.replace(\".flytegen.\", \"\") + \"-auto_generated\"\n",
    "        \n",
    "        root_path = os.path.join(library_path, domain_name, project_name)\n",
    "        \n",
    "        folders = workflow_name.split(\".\")\n",
    "        file_name = folders.pop() + \".workflow\"\n",
    "        if len(folders) > 0:\n",
    "            folder_path = os.path.join(*folders)\n",
    "            folder_path = os.path.join(root_path, folder_path)\n",
    "        else:\n",
    "            folder_path = root_path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # print(\"folder_path: {}; file:{}; file_path: {}\".format(folder_path, file_name, file_path))\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "    \n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(\"workflow name: {}\".format(workflow_name))\n",
    "                \n",
    "    for i in range(0, task_latest_df.shape[0]):\n",
    "        domain_name = task_latest_df.at[i, \"domain\"]\n",
    "        project_name = task_latest_df.at[i, \"project\"]\n",
    "        task_name = task_latest_df.at[i, \"task_name\"]\n",
    "        if \".flytegen\" in task_name:\n",
    "            task_name = task_name.replace(\".flytegen.\", \"\") + \"-auto_generated\"\n",
    "        \n",
    "        root_path = os.path.join(library_path, domain_name, project_name)\n",
    "        \n",
    "        folders = task_name.split(\".\")\n",
    "        file_name = folders.pop() + \".task\"\n",
    "        if len(folders) > 0:\n",
    "            folder_path = os.path.join(*folders)\n",
    "            folder_path = os.path.join(root_path, folder_path)\n",
    "        else:\n",
    "            folder_path = root_path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # print(\"folder_path: {}; file:{}; file_path: {}\".format(folder_path, file_name, file_path))\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "    \n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(\"task name: {}\".format(task_name))\n",
    "                \n",
    "    for i in range(0, launchplan_latest_df.shape[0]):\n",
    "        domain_name = launchplan_latest_df.at[i, \"domain\"]\n",
    "        project_name = launchplan_latest_df.at[i, \"project\"]\n",
    "        launchplan_name = launchplan_latest_df.at[i, \"launchplan_name\"]\n",
    "        if \".flytegen\" in launchplan_name:\n",
    "            launchplan_name = launchplan_name.replace(\".flytegen.\", \"\") + \"-auto_generated\"\n",
    "        \n",
    "        root_path = os.path.join(library_path, domain_name, project_name)\n",
    "        \n",
    "        folders = launchplan_name.split(\".\")\n",
    "        file_name = folders.pop() + \".launchplan\"\n",
    "        if len(folders) > 0:\n",
    "            folder_path = os.path.join(*folders)\n",
    "            folder_path = os.path.join(root_path, folder_path)\n",
    "        else:\n",
    "            folder_path = root_path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # print(\"folder_path: {}; file:{}; file_path: {}\".format(folder_path, file_name, file_path))\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "    \n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(\"launchplan name: {}\".format(launchplan_name))\n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac29e1cd98374d9a"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:57:41.429106Z",
     "start_time": "2024-03-05T23:57:41.423908Z"
    }
   },
   "id": "ff8918bc82fbf221"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "40c03f033626be7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
